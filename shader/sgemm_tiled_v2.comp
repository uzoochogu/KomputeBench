// Derived from https://github.com/tpoisonooo/how-to-optimize-gemm/
// Tiled MatMul kernel (MMult_vk_1)
#version 450

#define TS 16u

layout(local_size_x = TS, local_size_y = TS) in;

layout(set = 0, binding = 0) readonly buffer buf_in_tensor_1 {
  float in_tensor_1[];
};
layout(set = 0, binding = 1) readonly buffer buf_in_tensor_2 {
  float in_tensor_2[];
};
layout(set = 0, binding = 2) writeonly buffer buf_out_tensor {
  float out_tensor[];
};

layout(constant_id = 0) const float tensor_size_f = 0;

shared float sub_tensor_1[TS][TS];
shared float sub_tensor_2[TS][TS];

void main() {
  uint block = TS;
  uint tensor_size = uint(tensor_size_f);
  uint loop = tensor_size / block;

  uint threadIdx = gl_LocalInvocationID.x;
  uint threadIdy = gl_LocalInvocationID.y;

  uint globalCol = gl_WorkGroupID.y * block + threadIdy;
  uint globalRow = gl_WorkGroupID.x * block + threadIdx;

  float acc = 0.0;
  for (uint i = 0u; i < loop; ++i) {
    sub_tensor_1[threadIdy][threadIdx] =
        in_tensor_1[tensor_size * globalCol + i * block + threadIdx];
    sub_tensor_2[threadIdy][threadIdx] =
        in_tensor_2[tensor_size * (i * block + threadIdy) + globalRow];

    memoryBarrierShared();
    barrier();

    for (uint k = 0u; k < block; ++k) {
      acc += sub_tensor_1[threadIdy][k] * sub_tensor_2[k][threadIdx];
    }
    barrier();
  }

  out_tensor[(globalCol * tensor_size) + globalRow] = acc;
}
